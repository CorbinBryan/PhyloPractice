# Introduction to Maximum Likelihood and Bayesian Inference: 
## Introduction:
When measurements or data of any sort is collected, it is assumed to follow a **probability distribution**. Any measurement assumed to be distributed according to some known distribution is called a **random variable**, as we assume these values are generated by a stochastic process--a process with some degree of randomness, for lack of a better word. There are many "canonical" probability distributions, each with a different use case and it's own unique set of mathematical properties. These mathematical properties provide a set of equations that describe the distribution in terms of variables known as **parameters**. One equation, termed either the probability mass function, in the case of **discrete random variables** or the probability density function in the case of **continuous random variables**, is of immense importance because it allows us to calculate the probability of observed data in terms of some parameter. 

Let $\theta$ be some parameter of a random variable $X$ with observations $X=\{x_1,x_2,x_3, ..., x_n\}$ and $f(x;\theta)$ be the probability density function of $X$ given some value of $\theta$. Often times, you want to find the value of $\theta$ in this function given some observed data. This does not change the "shape" of the function (i.e., the actual function), but does change how we think about it and what we call it. In this instance, we call it the likelihood function, which is typically given in the following notation: 
$$
L(\theta;x)
$$
Once again, the actual mathematics of the function does not change. What you're using the function for, does change. Probability mass/denisty functions are used to calculate the probability of an observation (or many of them). Likelihood functions are used to calculate parameters. 
## Maximum Likelihood Inference: 
Maximum Likelihood inference is at the core of _a lot_ of modern analyses. It is seriously important. 

When you have a full data set, the probability of observing the entire data set is equal to the product of the probabilities of all its observations, which are assumed to be **idenpendent and identically distributed**. Let $X=\{x_1,x_2,x_3,...,x_n \}$ be some random variable of a known distribution with n observations. Accordingly, the probability of the observed data $P(X;\theta)$ can be written as such:
$$
P(X;\theta)=\prod_x p(x; \theta)
$$
Knowing what we do about likelihood functions, we obtain the following: 
$$
L(\theta;x)=\prod_x p(x; \theta)
$$
For a given probability distribution, we can use this equation to determine the best value of $\theta$ by finding the value that maximizes this likelihood function. Recall that the actual equation that $p(x;\theta)$ represents is dependent on the type of probability distribution that random variable follows. Basically, this process determines the parameter estimates that best describe the observed data. There's some nuance in the actual determination of the value of the parameter, but we mustn't get into those here. 